```yaml
name: CI

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10']
        pip: ['pandas<1', 'pandas>=1.0.3', 'swifter']
    env:
      JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
      HADOOP_VERSION: 2.7
      SPARK_DIRECTORY: ../
      SPARK_HOME: ../spark/
      ARROW_PRE_0_15_IPC_FORMAT: 1
      SPARK_LOCAL_IP: 127.0.0.1
    steps:
      - uses: actions/checkout@v2

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      - name: Upgrade pip, setuptools, and wheel
        run: |
          python -m pip install --upgrade pip setuptools wheel

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements_test.txt
          pip install ${{ matrix.pip }}

      - name: Set SPARK_VERSION
        run: |
          if [ "${{ matrix.python-version }}" = "3.8" ]; then
            echo "SPARK_VERSION=3.0.1" >> $GITHUB_ENV
          else
            echo "SPARK_VERSION=2.4.7" >> $GITHUB_ENV
          fi

      - name: Install Spark
        run: make install-spark-ci

      - name: Build and check distribution
        run: |
          python setup.py sdist bdist_wheel
          twine check dist/*

      - name: Install package
        run: make install

      - name: Run tests
        run: |
          pytest -m "not spark_test" tests/
          pytest -m spark_test tests/

  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Set up Python 3.9
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements_test.txt

      - name: Run linting
        run: make lint
```