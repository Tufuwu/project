```yaml
name: CI

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.9', '3.10', '3.11']
        pip-version: ['pandas<1', 'pandas>=1.0.3', 'swifter']
    env:
      JAVA_HOME: /usr/lib/jvm/java-8-openjdk-amd64
      HADOOP_VERSION: 2.7
      SPARK_DIRECTORY: ../
      SPARK_HOME: ../spark/
      ARROW_PRE_0_15_IPC_FORMAT: 1
      SPARK_LOCAL_IP: 127.0.0.1

    steps:
    - uses: actions/checkout@v2

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v2
      with:
        python-version: ${{ matrix.python-version }}

    - name: Upgrade pip, setuptools, wheel
      run: python -m pip install --upgrade pip setuptools wheel

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements_test.txt
        pip install ${{ matrix.pip-version }}
        if [ "${{ matrix.python-version }}" = "3.11" ]; then
          echo "export SPARK_VERSION=3.0.1" >> $GITHUB_ENV
        else
          echo "export SPARK_VERSION=2.4.7" >> $GITHUB_ENV
        fi
        make install-spark-ci

    - name: Build and check distribution
      run: |
        python setup.py sdist bdist_wheel
        twine check dist/*
        make install

    - name: Run tests (without spark_test)
      run: pytest -m "not spark_test" tests/

    - name: Run spark tests
      run: pytest -m spark_test tests/

  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2

    - name: Set up Python 3.9
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -r requirements_test.txt

    - name: Linting
      run: make lint
```